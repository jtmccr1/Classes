---
title: "Lab8"
author: "JT McCrone"
date: "October 20, 2014"
output: html_document
---
```{r}
require(ggplot2)
require(plyr)
require(emdbook)
require(reshape2)


```

### Exercise 2

This exercise is about determining the day of reckoning for a lab that has 100 test tubes that each break with the probability of 0.05% each day.  The day of reckoning is day that the lab runs out of test tubes completely, halting all potential for productive science ( assuming it only takes 1 test tube to explore what the lab studies) .

First I modeled the number of available test tubes over time in 1E5 labs.


```{r}
labs<-1E5  # The number of labs
N<-matrix(data=0,nrow=400,ncol=labs)
N[1,]<-rep(x=100,times=labs)     # We begin with 100 test tubes

t<-1  # We set t =1 above
while(any(N[t,]>0)){
  t<-t+1
N[t,]<-rbinom(n=labs,size=N[t-1,],prob=0.95)
}

matplot(N[,1:5],type='l',lty=1)

```


Now for each lab I calculate the first day the lab is without any test tubes, and plot the distribution.  



```{r}
### Expected time to loss


day.of.rec<-data.frame(dor=apply(N,2,function(x) min(which(x==0))))

expected.day.of.rec<-mean(day.of.rec$dor)
var.day.of.rec<-var(day.of.rec)

print(paste0("The expected day of reckoning is ",expected.day.of.rec, " with a variance of ", var.day.of.rec))

ggplot(data=day.of.rec,mapping=aes(x=dor))+geom_histogram(binwidth=1,fill=NA,color='black', mapping=aes(y=..density..))+
  theme_bw()+labs(y="Probability",x="Day of Reckoning")
```

It looks like in most cases a lab in this situation will run out of test tubes around 75 to 125 days.  There is a long tail to distribution suggesting in some rare cases the lab will stay productive quite a bit longer than the average case ~100 days, which I suppose is good news for science.

### Exercise 13 

Here we are looking to use the method of moments to analyze seed predation data.  I'll break the data up by species, distance, and number of seeds available, and model the distributions using a betabinomial model.  I'll then try to infer some biologically relevant information regarding the probability of a given seed being taken based on these variables.  
```{r}

seeds <- read.csv("http://kinglab.eeb.lsa.umich.edu/480/data/seedpred.csv",
                  comment.char="#",
colClasses=c(date="Date",station='factor', dist='factor',species='factor'))
seeds <- arrange(seeds,station,dist,species,date)
ddply(seeds,~station+dist+species,summarize,
      avail=head(seeds,-1),
      taken=-diff(seeds),
      tint=diff(date)) -> dat
subset(dat,avail>0) -> dat


data.bb<-ddply(dat, .(dist,species,avail), function(x){ summarize(x,
                                                 n = unique(avail),
                                                 p=mean(taken)/n,
                                                 theta =-n*(mean(taken)*(mean(taken)-n)+var(taken))/((mean(taken)*(mean(taken)-n)+n*var(taken))),
                                                 dist = unique(dist),
                                                 species = unique(species)
                                                 )})

head(data.bb)

```
Now I'll check how well this model works for a few of the distributions, as it would take many plots to explore them all.


```{r}
fiveseeds <- subset(dat,avail==5 & dist == 10 & species %in% c("abz","cd","cor","dio") )
pl <- ggplot(data=fiveseeds,mapping=aes(x=taken))+
geom_histogram(binwidth=1,fill=NA,color='black', mapping=aes(y=..density..))+
  theme_bw()+facet_wrap(~species) 

fiveseed.bb<-subset(data.bb,avail==5 & dist == 10 & species %in% c("abz","cd","cor","dio") )

x<-seq(0,5)

pdf<-apply(fiveseed.bb,1,function(y) dbetabinom(x=x,prob=as.numeric(y["p"]),
                                                size=as.numeric(y["n"]),
                                                theta=as.numeric(y["theta"])))
pdf<-data.frame(cbind(pdf,x))
fiveseed.bb$species<-as.character(fiveseed.bb$species)
names(pdf)<-c(as.character(fiveseed.bb$species),"x")

pdf.long<-melt(pdf,id.vars = .(x))
pdf.long<-rename(pdf.long,c("variable"="species","value" = "bb"))

pl+geom_point(data=pdf.long,aes(x=x+0.5,y=bb),size=5)+facet_wrap(~species)+ggtitle("Seed Predation at Distance = 10")

```

These models seems to match the data reasonably well, but it would take more complex methods to determine how well they fit and our confidence with the estimations.

Also, ideally I want to talk about the probability of seeds being taken given their species, and/or distance from the forest.  However it's not obvious or trivial how to obtain single estimates from my analysis above.  For each species and distance I have up to 5 models one each every possiblity for the number of seeds available.  To combine the estimated parameters into one, I suppose I could average, but I think it would have to be weighted and even then the manner of weighting the parameters is not straight forward.

Here I will just look at the distance 10 and the species I plotted above. 

```{r}
fiveseed.bb
```
So it seems when 5 seeds are available under these conditions  "cd" is the most likely to be taken; however, I don't have any estimates of confidence for this observation and so it's hard to say if "cd" is actually more likely to be taken than other species say "abz".  The difficulty discussed above is seen when we look at the same species at the same distance when there are differences in the number of available seeds.

```{r}
fourseed.bb<-subset(data.bb,avail==4 & dist == 10 & species %in% c("abz","cd","cor","dio") )
fourseed.bb

```
Now "abz" is the most-likely to be taken and all the probabilities are different than when there were 5 seeds present.  But I don't expect there is a change in the process here.  It should be the same binomial distribution just with a different n.  So what is the real p?  If I understood class today we can find it by using maximum likelihood estimators.
